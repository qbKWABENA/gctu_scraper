name: GCTU News Scraper Bot
on:
  schedule:
    - cron: '0 8 * * *'  # Runs daily at 8:00 AM UTC
  workflow_dispatch:     # Enable manual triggers

jobs:
  scrape-and-notify:
    runs-on: ubuntu-latest
    
    steps:
      # Step 1: Checkout repository code
      - name: Checkout code
        uses: actions/checkout@v4

      # Step 2: Set up Python
      - name: Set up Python 3.10
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      # Step 3: Install dependencies
      - name: Install Python packages
        run: |
          python -m pip install --upgrade pip
          pip install \
            requests==2.31.0 \
            beautifulsoup4==4.12.2 \
            python-telegram-bot==20.3 \
            python-dotenv==1.0.0 \
            lxml==4.9.3

      # Step 4: Run your scraper
      - name: Execute scraper
        env:
          BOT_TOKEN: ${{ secrets.BOT_TOKEN }}      # From GitHub Secrets
          CHANNEL_ID: ${{ secrets.CHANNEL_ID }}    # From GitHub Secrets
        run: |
          python scraper.py

      # (Optional) Step 5: Notify on failure
      - name: Notify on failure
        if: failure()
        uses: actions/github-script@v6
        with:
          script: |
            github.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: '⚠️ Scraper failed! Check the workflow run: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}'
            })
